{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# train.py\n",
    "# this file is material part of of the dissertation 'Deep Learning for Emotion Recognition in Cartoons'\n",
    "# [c] 2016-2017 John Wesley Hill\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard, Callback\n",
    "from keras.utils import to_categorical as one_hot\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import optimizers\n",
    "\n",
    "from vis.utils import utils\n",
    "from vis.visualization import visualize_activation, visualize_saliency, get_num_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_version = \"v1.6\"\n",
    "emotions = [\"happy\", \"angry\", \"surprise\", \"sad\", \"fear\", \"disgust\"]\n",
    "w, h = (60, 60)\n",
    "epochs = 50\n",
    "\n",
    "COLOR = {\n",
    "\t'G':'\\x1B[32m',\n",
    "\t'R':'\\x1B[31m',\n",
    "\t'RS':'\\x1B[0m'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PlotStats callback for printing custom plot stats of the model.\n",
    "class PlotStats(Callback):\n",
    "\tdef on_train_end(self, logs={}):\n",
    "\t\t# model loss plot.\n",
    "\t\tplt.plot(self.losses)\n",
    "\t\tplt.plot(self.val_losses,  color=\"green\")\n",
    "\t\tplt.title('Learning curve for model loss')\n",
    "\t\tplt.ylabel('loss')\n",
    "\t\tplt.xlabel('epochs ({})'.format(epochs))\n",
    "\t\tplt.legend(['training', 'testing'], loc='upper left')\n",
    "\t\tplt.savefig('model_{}_loss.png'.format(model_version))\n",
    "\t\tplt.gcf().clf()\n",
    "\t\t\n",
    "\t\t# model accuracy plot.\n",
    "\t\tplt.plot(self.acc)\n",
    "\t\tplt.plot(self.val_acc,  color=\"green\")\n",
    "\t\tplt.title('Learning curve for model accuracy'.format(epochs))\n",
    "\t\tplt.ylabel('accuracy')\n",
    "\t\tplt.xlabel('epochs ({})'.format(epochs))\n",
    "\t\tplt.legend(['training', 'testing'], loc='upper left')\n",
    "\t\tplt.savefig('model_{}_accuracy.png'.format(model_version))\n",
    "\t\tplt.gcf().clf()\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\tdef on_train_begin(self, logs={}):\n",
    "\t\tself.losses = []\n",
    "\t\tself.acc = []\n",
    "\t\tself.val_acc = []\n",
    "\t\tself.val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\tdef on_epoch_end(self, batch, logs={}):\n",
    "\t\tself.losses.append(logs.get('loss'))\n",
    "\t\tself.val_losses.append(logs.get('val_loss'))\t\t\n",
    "\t\tself.acc.append(logs.get('acc'))\n",
    "\t\tself.val_acc.append(logs.get('val_acc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loads the emotion datasets and constructs them into numpy arrays \n",
    "# for training & testing for a character.\n",
    "def load_emotion_data_for(character):\n",
    "\tDATASETS = {\n",
    "\t\t'happy': {\n",
    "\t\t\t'training':'datasets/' + character + '/happy/training',\n",
    "\t\t\t'testing':'datasets/'  + character + '/happy/testing',\n",
    "\t\t},\n",
    "\t\t'angry': {\n",
    "\t\t\t'training':'datasets/' + character + '/angry/training',\n",
    "\t\t\t'testing':'datasets/'  + character + '/angry/testing',\n",
    "\t\t},\n",
    "\t\t'surprise': {\n",
    "\t\t\t'training':'datasets/' + character + '/surprise/training',\n",
    "\t\t\t'testing':'datasets/'  + character + '/surprise/testing',\n",
    "\t\t}\n",
    "\t}\n",
    "\temotions_training = []\n",
    "\temotions_testing = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\t# training\n",
    "\t# append paths for happy training...\n",
    "\tfor hd_train in os.listdir(DATASETS['happy']['training']):\n",
    "\t\temotions_training.append(os.path.join(DATASETS['happy']['training'], hd_train))\n",
    "\t\t\n",
    "\t# append paths for angry training...\n",
    "\tfor ad_train in os.listdir(DATASETS['angry']['training']):\n",
    "\t\temotions_training.append(os.path.join(DATASETS['angry']['training'], ad_train))\n",
    "\t\n",
    "\t# Append paths for surprise training...\n",
    "\tfor sp_train in os.listdir(DATASETS['surprise']['training']):\n",
    "\t\temotions_training.append(os.path.join(DATASETS['surprise']['training'], sp_train))\n",
    "\t\n",
    "\t# todo: append paths for other emotions for training...\n",
    "\t# ...\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\t# testing\n",
    "\t# append paths for happy testing...\n",
    "\tfor hd_test in os.listdir(DATASETS['happy']['testing']):\n",
    "\t\temotions_testing.append(os.path.join(DATASETS['happy']['testing'], hd_test))\n",
    "\t\t\n",
    "\t# append paths for angry testing...\n",
    "\tfor ad_test in os.listdir(DATASETS['angry']['testing']):\n",
    "\t\temotions_testing.append(os.path.join(DATASETS['angry']['testing'], ad_test))\n",
    "\t\n",
    "\t# append paths for surprise testing...\n",
    "\tfor sp_test in os.listdir(DATASETS['surprise']['testing']):\n",
    "\t\temotions_testing.append(os.path.join(DATASETS['surprise']['testing'], sp_test))\n",
    "\t\t\n",
    "\t# todo: append paths for other emotions for testing...\n",
    "\t# ...\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\tdata_size = len(emotions_training) // len(DATASETS.keys())\n",
    "\t\n",
    "\t# labels\n",
    "\t# happy labels / label 0\n",
    "\thappy_labels_train = np.zeros(data_size)\n",
    "\thappy_labels_test = np.zeros(data_size)\t\n",
    "\t\n",
    "\t# angry labels / label 1 (fill with ones)\n",
    "\tangry_labels_train = np.zeros(data_size)\n",
    "\tangry_labels_train.fill(1)\n",
    "\tangry_labels_test = np.zeros(data_size)\n",
    "\tangry_labels_test.fill(1)\n",
    "\t\n",
    "\t# surprise labels / label 2 (fill with ones)\n",
    "\tsurprise_labels_train = np.zeros(data_size)\n",
    "\tsurprise_labels_train.fill(2)\n",
    "\tsurprise_labels_test = np.zeros(data_size)\n",
    "\tsurprise_labels_test.fill(2)\n",
    "\t\n",
    "\t# todo: other emotion labels / label n (fill with n's) (see the emotion array)\n",
    "\t# ...\n",
    "\t\n",
    "\t# append training & testing emotion labels.\n",
    "\temotion_training_labels = np.append(happy_labels_train, angry_labels_train)\n",
    "\temotion_training_labels = np.append(emotion_training_labels, surprise_labels_train)\n",
    "\t\n",
    "\temotion_testing_labels = np.append(happy_labels_test, angry_labels_test)\n",
    "\temotion_testing_labels = np.append(emotion_testing_labels, surprise_labels_test)\n",
    "\t\n",
    "\tprint \"(training) loaded {} images & {} labels for {}...\".format(len(emotions_training), len(emotion_training_labels), character)\n",
    "\tprint \"(testing) loaded {} images & {} labels for {}...\".format(len(emotions_testing), len(emotion_testing_labels), character)\n",
    "\t\n",
    "\treturn (emotions_training, emotion_training_labels), (emotions_testing, emotion_testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# process images into numpy for training & testing.\n",
    "def process_images(fp):\n",
    "\timgs = []\n",
    "\tfor f in fp:\n",
    "\t\timg = load_img(f)\n",
    "\t\timg = img.resize((w,h), Image.ANTIALIAS)\n",
    "\t\timg = img_to_array(img) / 255\n",
    "\t\timg = img.reshape(3, w, h)\n",
    "\t\timgs.append(img)\n",
    "\treturn np.array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display an image with a or without a label in matplotlib.\n",
    "def show_image(i, l=None):\n",
    "\tplt.imshow(array_to_img(i[0].reshape(3, w, h)))\n",
    "\tif l is not None:\n",
    "\t\tprint \"label: {}\".format(emotions[np.argmax(l[0])])\n",
    "\tplt.axis('off')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fetches a random image from a given dataset.\n",
    "# returns a numpy image, the original image and the ground truth label.\n",
    "def random_image_from_dataset(i, gtl):\n",
    "\tri = np.random.choice(len(i))\n",
    "\tnumpy_img = i[ri]\n",
    "\torig = array_to_img(numpy_img.reshape(3, w, h))\n",
    "\tnumpy_img = i[ri].reshape(1, 3, w, h)\n",
    "\treturn numpy_img, orig, gtl[ri]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# configuration before classification and training.\n",
    "def setup(reproduce=True):\n",
    "\t# fix the seed to reproduce results in this dissertation.\n",
    "\tseed = 12379231\n",
    "\tif reproduce is True:\n",
    "\t\tnp.random.seed(seed)\n",
    "\tplt.rc('text', usetex=True)\n",
    "\tplt.rc('font', family='serif')\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# callbacks for keras.\n",
    "def load_callbacks():\n",
    "\t# log to tensorboard for debugging and training + testing metrics.\n",
    "\tif not os.path.exists('datasets/logs'):\n",
    "\t\tos.mkdir('datasets/logs')\n",
    "\tps = PlotStats()\n",
    "\ttb = TensorBoard(log_dir='./datasets/logs', histogram_freq=1, write_graph=True, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "\treturn [tb, ps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# main dataset loader for tom and jerry.\n",
    "def load_dataset():\n",
    "\ttom_training, tom_testing = load_emotion_data_for(\"tom\")\n",
    "\tjerry_training, jerry_testing = load_emotion_data_for(\"jerry\")\n",
    "\t\n",
    "\ttraining_i = np.append(tom_training[0], jerry_training[0])\n",
    "\ttraining_l = np.append(tom_training[1], jerry_training[1])\n",
    "\t\n",
    "\ttesting_i = np.append(tom_testing[0], jerry_testing[0])\n",
    "\ttraining_l = np.append(tom_testing[1], jerry_testing[1])\n",
    "\t\n",
    "\treturn (training_i, training_l), (testing_i, training_l)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perform training.\n",
    "def load_training_and_testing_data():\n",
    "\tprint \"loading training & testing data...\"\n",
    "\ttraining, testing = load_dataset()\n",
    "\n",
    "\t# process testing and training images -> numpy arrays.\n",
    "\ttrain_images = process_images(training[0])\n",
    "\ttest_images = process_images(testing[0])\n",
    "\t\n",
    "\t# convert training and testing to one hot vectors.\n",
    "\ttrain_labels = one_hot(training[1], num_classes=6)\n",
    "\ttest_labels = one_hot(testing[1], num_classes=6)\n",
    "\t\n",
    "\t# shuffle training data in sync for better training.\n",
    "\trng = np.random.get_state()\n",
    "\tnp.random.shuffle(train_images)\n",
    "\tnp.random.set_state(rng)\n",
    "\tnp.random.shuffle(train_labels)\n",
    "\t\n",
    "\t# partition dataset 80/20. (80 -> training, 20 -> testing)\n",
    "\tr = np.random.rand(train_images.shape[0])\n",
    "\tpart = r < np.percentile(r, 80)\n",
    "\ttrain_images = train_images[part]\n",
    "\ttrain_labels = train_labels[part]\n",
    "\ttest_images = test_images[-part]\n",
    "\ttest_labels = test_labels[-part]\n",
    "\t\n",
    "\t# optionally show images and labels.\n",
    "\t# show_image(train_images, train_labels)\n",
    "\t# show_image(test_images, test_labels)\n",
    "\treturn train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train images and test labels.\n",
    "def train(train_i, train_l, test_i, test_l, visualise, summary):\n",
    "\t# additional callbacks to aid training and viewing plots and visualisations.\n",
    "\tcb = load_callbacks()\n",
    "\t\n",
    "\t# load our cnn model.\n",
    "\tcnn = load_cnn_model()\n",
    "\t\n",
    "\t# begin training and save the model when finished.\n",
    "\tif not os.path.isfile('model_{}_.h5'.format(model_version)):\n",
    "\t\tprint \"training...\"\n",
    "\t\tcnn.fit(train_i, train_l, epochs=epochs, batch_size=32, verbose=1, callbacks=cb, validation_data=(test_i, test_l))\n",
    "\t\t# after training, save the weights.\n",
    "\t\tcnn.save_weights('model_{}_.h5'.format(model_version))\n",
    "\t\n",
    "\t# load the weights if they exist.\n",
    "\tcnn.load_weights('model_{}_.h5'.format(model_version))\n",
    "\t\n",
    "\t# model evaluation. \n",
    "\tloss, acc = cnn.evaluate(test_i, test_l, verbose=0)\n",
    "\tprint \"model loss {:.1f}%\".format(loss)\n",
    "\tprint \"model accuracy {:.1f}%\\n\".format(acc)\n",
    "\t\n",
    "\t# print summary if true.\n",
    "\tif summary is True:\n",
    "\t\tprint \"summary:\"\n",
    "\t\tcnn.summary()\n",
    "\t\n",
    "\n",
    "\tif visualise is True:\n",
    "\t\t# show at least n test results for testing.\n",
    "\t\tn = 10\n",
    "\t\tfor e, i in enumerate(range(n)):\n",
    "\t\t\t# fetch a random image.\n",
    "\t\t\ti, original, gtl = random_image_from_dataset(test_i, test_l)\n",
    "\t\t\tplt.imshow(original)\n",
    "\t\t\tplt.axis('off')\n",
    "\t\t\t\n",
    "\t\t\tprint \"sample image: {}\\n---\".format(e+1)\n",
    "\t\t\t\n",
    "\t\t\t# get the predicted class and the predicted probabilities.\n",
    "\t\t\tpred_class, prob = (cnn.predict_classes(i, verbose=0)[0], cnn.predict(i, verbose=0).flatten())\n",
    "\t\t\tpredicted_emotion = str(emotions[pred_class])\n",
    "\t\t\tground_truth_emotion = str(emotions[np.argmax(gtl)])\n",
    "\t\t\tconfidence_score = float(prob[pred_class] * 100)\n",
    "\t\t\t\n",
    "\t\t\t# check if the label match the prediction.\n",
    "\t\t\tif ground_truth_emotion is predicted_emotion:\n",
    "\t\t\t\tplt.text(3, 7, predicted_emotion.title(), fontsize=36, color=\"lime\")\n",
    "\t\t\t\tprint \"image prediction: {} | confidence score: ({:.1f}%)\".format(COLOR['G'] + predicted_emotion + COLOR['RS'], confidence_score)\n",
    "\t\t\telse:\n",
    "\t\t\t\tplt.text(3, 7, predicted_emotion.title(), fontsize=36, color=\"red\")\n",
    "\t\t\t\tprint \"image prediction: {} | confidence score: ({:.1f}%)\".format(COLOR['R'] + predicted_emotion + COLOR['RS'], confidence_score)\t\n",
    "\t\t\t\t\n",
    "\t\t\t# display the closer emotion probabilities.\n",
    "\t\t\tfor p in np.argsort(-prob):\n",
    "\t\t\t\tprint \"{}: {:.1f}%\".format(str(emotions[p]), float(prob[p] * 100))\n",
    "\t\t\t\n",
    "\t\t\t# display the ground truth emotion.\n",
    "\t\t\tprint \"ground truth: {}\\n\".format(COLOR['G'] + str(ground_truth_emotion) + COLOR['RS'])\n",
    "\t\t\tplt.show()\n",
    "\t\t\tplt.gcf().clf()\n",
    "\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the main convolutional neural network architecture.\n",
    "def load_cnn_model():\n",
    "\t# define convnet model.\n",
    "\tcnn = Sequential()\n",
    "\t\n",
    "\t# 3x3 convolution & 2x2 maxpooling with a input image of 60x60x3.\n",
    "\tcnn.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(3, w, h), name=\"conv_layer_1\"))\n",
    "\tcnn.add(MaxPooling2D(pool_size=(2, 2), name='maxpool_1'))\n",
    "\n",
    "\t# 3x3 convolution & 2x2 maxpooling.\n",
    "\tcnn.add(Conv2D(32, (3, 3), activation='relu', padding='same', name='conv_layer_2'))\n",
    "\tcnn.add(MaxPooling2D(pool_size=(2, 2), name='maxpool_2'))\n",
    "\n",
    "\t# 3x3 convolution & 9x9 maxpooling.\n",
    "\tcnn.add(Conv2D(32, (3, 3), activation='relu', padding='same', name='conv_layer_3'))\n",
    "\tcnn.add(MaxPooling2D(pool_size=(9, 9), name='maxpool_3'))\n",
    "\n",
    "\t# dropout 50% and flatten layer.\n",
    "\tcnn.add(Dropout(0.5))\n",
    "\tcnn.add(Flatten(name='flatten_1'))\n",
    "\t\n",
    "\t# fully connected layers and the output layer.\n",
    "\tcnn.add(Dense(512, activation='relu', name='fully_connected_1'))\n",
    "\tcnn.add(Dense(6, activation='softmax', name='output_layer'))\n",
    "\to = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\tcnn.compile(loss='categorical_crossentropy', optimizer=o, metrics=['accuracy'])\n",
    "\t\n",
    "\t# return the cnn model.\n",
    "\treturn cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classify an emotion from an image.\n",
    "def classify_emotion_from_image(local_image):\n",
    "\t# classify input image, if it exists.\n",
    "\tif os.path.isfile('model_{}_.h5'.format(model_version)):\n",
    "\t\tprint \"loading model...\"\n",
    "\t\tcnn = load_cnn_model()\n",
    "\t\tcnn.load_weights('model_{}_.h5'.format(model_version))\n",
    "\t\n",
    "\t\t# load local image.\n",
    "\t\tloaded_img = process_images(local_image)\n",
    "\t\tprint \"classifying...\"\n",
    "\t\t\n",
    "\t\t# get the predicted class and the predicted probabilities.\n",
    "\t\tpred_class, prob = (cnn.predict_classes(loaded_img, verbose=0)[0], cnn.predict(loaded_img, verbose=0).flatten())\n",
    "\t\tpredicted_emotion = str(emotions[pred_class])\n",
    "\t\tconfidence_score = float(prob[pred_class] * 100)\n",
    "\t\tprint \"image: {}\\n---\".format(sys.argv[2])\n",
    "\t\tprint \"image prediction: {} | confidence score: ({:.1f}%)\".format(COLOR['G'] + predicted_emotion + COLOR['RS'], confidence_score)\n",
    "\t\t\n",
    "\t\t# display the closer emotion probabilities.\n",
    "\t\tfor p in np.argsort(-prob):\n",
    "\t\t\tprint \"{}: {:.1f}%\".format(str(emotions[p]), float(prob[p] * 100))\n",
    "\t\t\n",
    "\t\t# display image.\n",
    "\t\tplt.text(3, 7, predicted_emotion.title(), fontsize=36, color=\"purple\")\n",
    "\t\tshow_image(loaded_img)\n",
    "\telse:\n",
    "\t\tprint \"unable to classify image \\'{}\\', model does not exist, train the network first.\".format(local_image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create visualisations, requires a predefined model.\n",
    "def vis(img):\n",
    "\tif os.path.isfile('model_{}_.h5'.format(model_version)):\n",
    "\t\tprint 'loading model...'\n",
    "\t\tcnn = load_cnn_model()\n",
    "\t\tcnn.load_weights('model_{}_.h5'.format(model_version))\n",
    "\t\t\n",
    "\t\t# list all layers in loaded model.\n",
    "\t\tlayer_name = \"output_layer\"\n",
    "\t\tlayer_idx = [idx for idx, layer in enumerate(cnn.layers) if layer.name == layer_name][0]\n",
    "\t\t\n",
    "\t\t# selected layers to visualise.\n",
    "\t\tlayers = ['conv_layer_1', 'conv_layer_2', 'conv_layer_3', 'output_layer']\n",
    "\t\t\n",
    "\t\t# visualise convnet visualisation for each layer, place them in a subplot.\n",
    "\t\tfor layer_name in layers:\n",
    "\t\t\tprint \"Generating visualisation of {}\".format(layer_name)\n",
    "\t\t\tlayer_idx = [idx for idx, layer in enumerate(cnn.layers) if layer.name == layer_name][0]\n",
    "\t\t\t\n",
    "\t\t\tif 'conv' not in layer_name:\t\n",
    "\t\t\t\tplt.figure()\n",
    "\t\t\t\tfor idx, e in enumerate(emotions):\n",
    "\t\t\t\t\tplt.subplot(6, 6, idx + 1)\n",
    "\t\t\t\t\tplt.text(1, 7, '{}'.format(e))\n",
    "\t\t\t\t\timg = visualize_activation(cnn, layer_idx, filter_indices=idx, max_iter=750)\n",
    "\t\t\t\t\timg = array_to_img(img.reshape(3, w, h))\n",
    "\t\t\t\t\tplt.axis('off')\n",
    "\t\t\t\t\tplt.imshow(img)\n",
    "\t\t\t\t\n",
    "\t\t\t\tplt.suptitle('Visualisation of the Output Layer')\n",
    "\t\t\t\tplt.savefig('{}.png'.format(layer_name), bbox_inches='tight')\n",
    "\t\t\t\tplt.show()\n",
    "\t\t\t\tbreak\n",
    "\t\t\t\n",
    "\t\t\tfilters = np.arange(get_num_filters(cnn.layers[layer_idx]))\n",
    "\t\t\t\n",
    "\t\t\timages = []\n",
    "\t\t\tfor idx in filters:\n",
    "\t\t\t\timg = visualize_activation(cnn, layer_idx, tv_weight=0, verbose=False, filter_indices=idx, max_iter=750)\n",
    "\t\t\t\timg = array_to_img(img.reshape(3, w, h))\n",
    "\t\t\t\timages.append(img)\n",
    "\t\t\t\n",
    "\t\t\tplt.figure()\n",
    "\t\t\tfor idx, i in enumerate(images):\n",
    "\t\t\t\tplt.subplots_adjust(wspace=0, hspace=0)\n",
    "\t\t\t\tplt.subplot(6, 6, idx + 1)\n",
    "\t\t\t\tplt.text(0, 15, 'Filter {}'.format(idx) )\n",
    "\t\t\t\tplt.axis('off')\n",
    "\t\t\t\tplt.imshow(i)\n",
    "\t\t\t\t\n",
    "\t\t\tplt.suptitle('Visualisation of Convolution Layer {}'.format(layer_name[len(layer_name)-1]))\n",
    "\t\t\tplt.savefig('{}.png'.format(layer_name), bbox_inches='tight')\n",
    "\t\t\tplt.show()\n",
    "\t\t\t\n",
    "\telse:\n",
    "\t\tprint 'model does not exist, train the network first.'\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\tvisualise_classification = False\n",
    "\tsummary = False\n",
    "\t\n",
    "\t# -V - visualise convnet layers.\n",
    "\tif '-V' in sys.argv[1:]:\n",
    "\t\tvis(sys.argv[2:])\n",
    "\t\t\n",
    "\t# -t - train or visualise classification or print a summary of the model.\n",
    "\telif '-t' in sys.argv[1:]:\n",
    "\t\ttrain_i, train_l, test_i, test_l = load_training_and_testing_data()\n",
    "\t\tif '-v' in sys.argv[1:]:\n",
    "\t\t\tvisualise_classification = True\n",
    "\t\tif '-s' in sys.argv[1:]:\n",
    "\t\t\tsummary = True\n",
    "\t\ttrain(train_i, train_l, test_i, test_l, visualise_classification, summary)\n",
    "\t\n",
    "\t\n",
    "\t# -c - classify, classifies one image from an existing model.\n",
    "\telif '-c' in sys.argv[1:]:\n",
    "\t\tif os.path.isfile(sys.argv[2]):\n",
    "\t\t\t# load image for classification.\n",
    "\t\t\tloaded_img = [sys.argv[2]]\n",
    "\t\t\tclassify_emotion_from_image(loaded_img)\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\tprint 'unable to classify image \\'{}\\', does not exist.'.format(sys.argv[2])\n",
    "\t\n",
    "\t\n",
    "\telse:\n",
    "\t\tprint '### Deep Learning for Emotion Recognition in Cartoons ###'\n",
    "\t\tprint 'training: (and show summary or results)'\n",
    "\t\tprint 'usage: train.py -t [-v|-s]\\n'\n",
    "\t\tprint 'classification:'\n",
    "\t\tprint 'usage: train.py -c image.jpg'\n",
    "\t\tprint 'visualisation:'\n",
    "\t\tprint 'usage: train.py -V'\n",
    "\t\t\n",
    "if __name__ == '__main__':\n",
    "\t# early setup\n",
    "\tsetup(False)\n",
    "\tK.set_image_dim_ordering('th')\n",
    "\tmain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
